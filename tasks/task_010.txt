# Task ID: 10
# Title: Migrate LLMServiceFactory to Use BaseFactory
# Status: in-progress
# Dependencies: 3, 4
# Priority: medium
# Description: Refactor the LLMServiceFactory to inherit from BaseFactory and eliminate duplicated code.
# Details:
Refactor `src/pytest_analyzer/core/infrastructure/llm/llm_service_factory.py` to use the new base class:

```python
from typing import Type, Optional, Dict, Any

from pytest_analyzer.core.infrastructure.base_factory import BaseFactory
from pytest_analyzer.core.interfaces.protocols import LLMService, LLMProvider
from pytest_analyzer.core.infrastructure.llm.openai_service import OpenAIService
from pytest_analyzer.core.infrastructure.llm.anthropic_service import AnthropicService
from pytest_analyzer.core.infrastructure.llm.mock_service import MockLLMService
from pytest_analyzer.core.cross_cutting.configuration.settings import Settings
from pytest_analyzer.core.cross_cutting.error_handling import error_context

class LLMServiceFactory(BaseFactory):
    """Factory for creating LLM services based on configuration."""

    def __init__(self, settings: Optional[Settings] = None):
        super().__init__(settings)
        self._register_default_services()

    def _register_default_services(self) -> None:
        """Register the default LLM services."""
        self.register("openai", OpenAIService)
        self.register("anthropic", AnthropicService)
        self.register("mock", MockLLMService)

    def create(self, provider_type: Optional[str] = None, provider: Optional[LLMProvider] = None) -> LLMService:
        """Create an LLM service with the specified provider.

        Args:
            provider_type: Type of LLM provider to use, or None to use settings
            provider: Optional pre-configured provider instance

        Returns:
            An instance of the appropriate LLM service
        """
        with error_context("Creating LLM service", self.logger):
            if provider_type is None:
                provider_type = self.settings.get("llm.provider", "openai")

            service_class = self.get_implementation(provider_type)
            return service_class(provider=provider, settings=self.settings)
```

This refactored factory uses the BaseFactory to eliminate code duplication while providing LLM service-specific functionality.

# Test Strategy:
Create unit tests for LLMServiceFactory that verify:
1. _register_default_services correctly registers all LLM services
2. create returns the correct service type based on provider_type
3. create uses settings to determine provider_type when not specified
4. create correctly passes provider and settings to the service constructor
5. Error handling for unsupported provider types
6. Verify that the refactored factory maintains the same behavior as the original implementation
