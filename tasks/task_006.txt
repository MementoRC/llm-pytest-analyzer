# Task ID: 6
# Title: Define Input/Output Schemas
# Status: done
# Dependencies: 1, 2
# Priority: high
# Description: Create Pydantic models for all MCP tool inputs and outputs to ensure proper validation and serialization.
# Details:
In `src/pytest_analyzer/mcp/schemas/`, implement:
1. Base request/response models
2. Tool-specific input schemas
3. Tool-specific output schemas
4. Error response schemas
5. Data transfer objects for complex objects

Implement schemas for all tools mentioned in the PRD:
- analyze_pytest_output
- run_and_analyze
- suggest_fixes
- apply_suggestion
- validate_suggestion
- get_failure_summary
- get_test_coverage
- get_config
- update_config

Example implementation:
```python
from pydantic import BaseModel, Field, validator
from typing import List, Optional, Dict, Any, Union
import os

class AnalyzePytestOutputRequest(BaseModel):
    file_path: str = Field(..., description="Path to pytest output file")

    @validator("file_path")
    def validate_file_exists(cls, v):
        if not os.path.exists(v):
            raise ValueError(f"File does not exist: {v}")
        return v

class FixSuggestion(BaseModel):
    file_path: str
    line_number: int
    original_code: str
    suggested_code: str
    confidence: float = Field(..., ge=0.0, le=1.0)
    explanation: str

class AnalyzePytestOutputResponse(BaseModel):
    suggestions: List[FixSuggestion]
    execution_time_ms: int
```

Ensure all schemas have proper validation, documentation, and examples.

# Test Strategy:
Unit test schema validation with valid and invalid inputs. Test serialization/deserialization of complex objects. Verify validation error messages are helpful. Test integration with MCP protocol handler. Check JSON schema generation for MCP compatibility.
