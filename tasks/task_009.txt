# Task ID: 9
# Title: Implement Core Analysis Tool: run_and_analyze
# Status: pending
# Dependencies: 6, 7, 8
# Priority: high
# Description: Implement the MCP tool for running pytest and analyzing the results in a single operation.
# Details:
In `src/pytest_analyzer/mcp/tools/analysis.py`, implement:
1. `run_and_analyze` tool function
2. Input validation for test paths and arguments
3. Sanitization of pytest arguments
4. Integration with MCPAnalyzerFacade
5. Timeout handling for long-running tests

Implementation should:
- Accept test path and optional pytest arguments
- Support quiet mode to suppress console output
- Validate path existence and argument safety
- Execute pytest with specified arguments
- Analyze results and return fix suggestions
- Include execution metrics

Example implementation:
```python
from pytest_analyzer.mcp.schemas import RunAndAnalyzeRequest, RunAndAnalyzeResponse
import shlex
import asyncio

async def run_and_analyze(request: RunAndAnalyzeRequest, facade: MCPAnalyzerFacade) -> RunAndAnalyzeResponse:
    # Validate test path
    if not os.path.exists(request.test_path):
        raise ValueError(f"Test path does not exist: {request.test_path}")
    
    # Sanitize pytest arguments
    safe_args = []
    if request.pytest_args:
        for arg in request.pytest_args:
            # Validate argument safety
            if arg.startswith("--") or arg.startswith("-"):
                safe_args.append(arg)
            else:
                # For positional args, ensure they're paths that exist
                if os.path.exists(arg):
                    safe_args.append(arg)
                else:
                    raise ValueError(f"Invalid pytest argument: {arg}")
    
    # Run with timeout
    try:
        result = await asyncio.wait_for(
            facade.run_and_analyze(request.test_path, safe_args, request.quiet),
            timeout=request.timeout_seconds or 30
        )
        return RunAndAnalyzeResponse(
            exit_code=result.exit_code,
            suggestions=result.suggestions,
            execution_time_ms=result.execution_time_ms,
            output=result.output if not request.quiet else None
        )
    except asyncio.TimeoutError:
        raise TimeoutError(f"Test execution timed out after {request.timeout_seconds or 30} seconds")
```

Register this tool with the MCP server during initialization.

# Test Strategy:
Unit test with mock facade. Test argument sanitization with valid and invalid inputs. Verify timeout handling works correctly. Test with various test paths and configurations. Integration test with actual pytest execution. Verify output capture in both quiet and verbose modes.
